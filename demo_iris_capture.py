#!/usr/bin/env python3
"""
Demo: Enhanced Live Recognition with Iris Image Capture
Shows the new image capture and display features
"""

import os
import sys
import time

def demo_iris_capture():
    """Demonstrate the enhanced iris capture features"""
    print("ğŸ¯ ENHANCED LIVE RECOGNITION DEMO")
    print("=" * 60)
    print("This demo shows the new iris image capture features:")
    print()
    print("ğŸ†• NEW FEATURES:")
    print("   ğŸ“¸ Automatic iris image capture when recognition occurs")
    print("   ğŸ‘ï¸  Real-time display of captured iris images")
    print("   ğŸ–¼ï¸  Composite images showing eye region + extracted iris")
    print("   ğŸ’¾ Organized storage in 'captured_iris' folder")
    print("   ğŸ” View all captured images in a grid layout")
    print()
    
    # Check if we have the required components
    try:
        from live_recognition import start_live_recognition
        from Main import getIrisFeatures
        print("âœ… Live recognition modules loaded")
    except ImportError as e:
        print("âŒ Import error: {}".format(e))
        return False
    
    # Check for trained model
    model = None
    if os.path.exists('model/best_model.h5'):
        try:
            import tensorflow as tf
            from tensorflow import keras
            model = keras.models.load_model('model/best_model.h5')
            print("âœ… Trained model loaded")
        except Exception as e:
            print("âš ï¸  Could not load model: {}".format(e))
            print("   Demo will run with basic eye detection only")
    else:
        print("âš ï¸  No trained model found")
        print("   Demo will run with basic eye detection only")
    
    print("\n" + "=" * 60)
    print("ğŸš€ STARTING ENHANCED LIVE RECOGNITION")
    print("=" * 60)
    
    print("\nğŸ“‹ ENHANCED CONTROLS:")
    print("   ğŸ”´ 'q' or ESC    â†’ Quit")
    print("   ğŸ“· 's'           â†’ Take screenshot")
    print("   ğŸ”„ 'r'           â†’ Reset statistics")
    print("   ğŸ‘ï¸  'i'           â†’ Toggle iris capture window ON/OFF")
    print("   ğŸ–¼ï¸  'c'           â†’ View all captured iris images")
    print()
    
    print("ğŸ’¡ WHAT TO EXPECT:")
    print("   1. Main window shows live video with eye detection")
    print("   2. When iris is recognized, image is automatically captured")
    print("   3. 'Captured Iris' window shows the latest captured image")
    print("   4. Press 'c' to see all captured images in a grid")
    print("   5. All images are saved in 'captured_iris/' folder")
    print()
    
    input("Press Enter to start the demo...")
    
    try:
        # Start the enhanced live recognition
        success = start_live_recognition(model=model, iris_extractor=getIrisFeatures)
        
        if success:
            print("\nâœ… Demo completed successfully!")
            
            # Show what was captured
            if os.path.exists('captured_iris'):
                captured_files = [f for f in os.listdir('captured_iris') if f.endswith('.jpg')]
                if captured_files:
                    print("\nğŸ“¸ CAPTURED IMAGES: {} files".format(len(captured_files)))
                    print("   Location: captured_iris/ folder")
                    print("   Files:")
                    for i, filename in enumerate(captured_files[-5:]):  # Show last 5
                        print("     {}. {filename}".format(i+1))
                    if len(captured_files) > 5:
                        print("     ... and {} more".format(len(captured_files) - 5))
                else:
                    print("\nğŸ“¸ No iris images were captured during this session")
                    print("   ğŸ’¡ Try positioning your eye closer to the camera")
                    print("   ğŸ’¡ Ensure good lighting conditions")
            
        else:
            print("\nâŒ Demo ended unexpectedly")
            print("   Check the error messages above for troubleshooting")
        
        return success
        
    except Exception as e:
        print("\nâŒ Demo error: {}".format(e))
        return False

def show_capture_folder_info():
    """Show information about the capture folder"""
    print("\n" + "=" * 60)
    print("ğŸ“ CAPTURE FOLDER INFORMATION")
    print("=" * 60)
    
    if os.path.exists('captured_iris'):
        files = [f for f in os.listdir('captured_iris') if f.endswith('.jpg')]
        total_size = sum(os.path.getsize(os.path.join('captured_iris', f)) for f in files)
        
        print(f"ğŸ“‚ Folder: captured_iris/")
        print("ğŸ“Š Files: {} iris images".format(len(files)))
        print("ğŸ’¾ Size: {} KB".format(total_size / 1024:.1f))
        
        if files:
            print(f"\nğŸ“‹ Recent files:")
            for filename in sorted(files)[-3:]:
                filepath = os.path.join('captured_iris', filename)
                size = os.path.getsize(filepath)
                print("   {} ({size} bytes)".format(filename))
        
        print(f"\nğŸ” File naming pattern:")
        print(f"   iris_person[ID]_[YYYYMMDD_HHMMSS_mmm].jpg")
        print(f"   Example: iris_person1_20241202_143052_123.jpg")
        
    else:
        print("ğŸ“‚ Capture folder not created yet")
        print("   Will be created automatically when first iris is captured")

def main():
    """Main demo function"""
    print("ğŸ‘ï¸ IRIS RECOGNITION - IMAGE CAPTURE DEMO")
    print("=" * 60)
    
    # Run the demo
    success = demo_iris_capture()
    
    # Show folder information
    show_capture_folder_info()
    
    print("\n" + "=" * 60)
    print("ğŸ“š SUMMARY OF NEW FEATURES")
    print("=" * 60)
    
    features = [
        "âœ¨ Automatic iris image capture during recognition",
        "ğŸ–¼ï¸  Real-time display in separate 'Captured Iris' window",
        "ğŸ“ Organized storage in 'captured_iris/' folder",
        "ğŸ¨ Composite images showing eye region + extracted iris",
        "ğŸ” Grid view of all captured images (press 'c')",
        "âš™ï¸  Toggle capture window on/off (press 'i')",
        "ğŸ“Š Person ID and confidence score labeling",
        "â° Timestamp-based file naming",
        "ğŸ’¾ Automatic cleanup (keeps last 50 images)",
        "ğŸ“ Console feedback for each capture"
    ]
    
    for feature in features:
        print("   {}".format(feature))
    
    print("\nğŸ’¡ USAGE TIPS:")
    print("   - Position your eye 12-18 inches from camera")
    print("   - Ensure good lighting (avoid shadows)")
    print("   - Look directly at the camera")
    print("   - Wait for green recognition box to appear")
    print("   - Check 'Captured Iris' window for real-time feedback")
    
    if success:
        print("\nğŸ‰ Demo completed successfully!")
    else:
        print("\nâš ï¸  Demo had issues - check error messages above")

if __name__ == "__main__":
    main()
